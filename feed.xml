<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">Trailblazer</title>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://home.iitk.ac.in/~avisingh/feed.xml" />
<link rel="alternate" type="text/html" href="http://home.iitk.ac.in/~avisingh" />
<updated>2015-02-10T06:40:33+00:00</updated>
<id>http://home.iitk.ac.in/~avisingh/</id>
<author>
  <name>Avi Singh</name>
  <uri>http://home.iitk.ac.in/~avisingh/</uri>
  <email>avisingh599@gmail.com</email>
</author>


<entry>
  <title type="html"><![CDATA[Technical Blogs]]></title>
  <link rel="alternate" type="text/html" href="http://home.iitk.ac.in/~avisingh/%5B%22bookmarks%22%5D/computer-vision-blogs/" />
  <id>http://home.iitk.ac.in/~avisingh/%5B%22bookmarks%22%5D/computer-vision-blogs</id>
  <updated>2014-12-28 18:01:55 +0000T00:00:00-00:00</updated>
  <published>2014-12-28T00:00:00+00:00</published>
  
  <author>
    <name>Avi Singh</name>
    <uri>http://home.iitk.ac.in/~avisingh</uri>
    <email>avisingh599@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;I always prefer reading blogs by hobbyists and researchers rather than textbooks, so I have decided to make a list of some of the good computer vision 
blogs that I have had the pleasure to  read.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computer Vision&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://eric-yuan.me/&quot;&gt;Eric Yuan’s Blog&lt;/a&gt;
This is the most extensive, and regularly updated CV blog that I have found so far. He also provides complete source codes (usually in C++/OpenCV), and
the his page has a nice, minimalistic interface. The frequency of posts has somewhat reduced after this guy started looking for a job (was earlier a master’s student at NYU).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://gilscvblog.wordpress.com/&quot;&gt;Gil’s CV Blog&lt;/a&gt; Some really good posts on feature detections and extraction, in which this guy completed a master’s. Most other posts provide source codes, not in-depth explanations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://computerblindness.blogspot.in/&quot;&gt;Computer Blindness&lt;/a&gt; Witty name. Not very active anymore. More of a news blog, not a technical one.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://aishack.in&quot;&gt;AI Shack&lt;/a&gt; Lots of programming tutorials for computer vision and machine learning.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Statistics&lt;/li&gt;
&lt;/ul&gt;

  &lt;p&gt;&lt;a href=&quot;http://home.iitk.ac.in/~avisingh/%5B%22bookmarks%22%5D/computer-vision-blogs/&quot;&gt;Technical Blogs&lt;/a&gt; was originally published by Avi Singh at &lt;a href=&quot;http://home.iitk.ac.in/~avisingh&quot;&gt;Trailblazer&lt;/a&gt; on December 28, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[The Power of Habit [1/3]]]></title>
  <link rel="alternate" type="text/html" href="http://home.iitk.ac.in/~avisingh/%5B%22review%22%5D/the-power-of-habit-1-slash-3/" />
  <id>http://home.iitk.ac.in/~avisingh/%5B%22review%22%5D/the-power-of-habit-1-slash-3</id>
  <updated>2014-09-29 21:11:30 +0000T00:00:00-00:00</updated>
  <published>2014-09-30T00:00:00+00:00</published>
  
  <author>
    <name>Avi Singh</name>
    <uri>http://home.iitk.ac.in/~avisingh</uri>
    <email>avisingh599@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Today I received two of the three books that I had impulsively ordered on Flipkart when I had too much free time on my hands (weekend after the midsem). One of the book is “Thinking, fast and slow”, by Daniel Kahneman, an Economics Nobel laureate who is hailed as the greatest psychologist of our time (or at least the back of the book says so). The book is not a regular popular science book (looking at you, Mr.Hawking), and is supposed to be a compilation of all the research done so far in the field of, well, ‘thinking’.&lt;/p&gt;

&lt;p&gt;I do not plan to complete the book anytime soon, and this post is about the other, lesser book that I arrived in my mail today. It is “The Power of Habit”, by Charles Duhigg (an NY Times business reporter). The book is divided into three parts, the first focuses on habits of individuals, the second on the habit of companies, and the third on the habit of societies. I went though the first part rapidly (forgetting the homework, the prelab report and the mini quiz that I had on tomorrow), and have decided to write this post as a summary of what I read.&lt;/p&gt;

&lt;p&gt;The book is mostly built on some of the recent neuroscience research carried out at the Brain and Cognitive Science Department of MIT. It talks about the Basal ganglia, also known as the ‘lizard’ brain (since lizards, and other primitive animals also posses it), and is responsible for some of our most primitive urges. It is this part of the brain where our habits reside. It tells us the story of a man who suffered severe brain damage, to the point that he could not even remember where the kitchen in his house was, but how the very same man had absolutely no trouble finding the kitchen whenever he felt hungry (courtesy the habit loop residing in his basal ganglia, which was untouched).&lt;/p&gt;

&lt;p&gt;The book tells us the story of Dungy, a football coach who led two NFL teams to victory in the super bowl, simply by changing the habit loops of the players, so that they did not waste any time ‘thinking’ on the field, and all their actions were ‘automatic’, just like human reflexes.&lt;/p&gt;

&lt;p&gt;It also tells us how the advertiser Claude Hopkins sold Pepsodent in a nation where almost no one was in the habit of brushing their teeth.&lt;/p&gt;

&lt;p&gt;But the main content of the book is how habits are formed, and what the essential parts of a habit loop are. A habit is basically &lt;/p&gt;
&lt;figure&gt;
	&lt;img src=&quot;/images/The-Habit-Loop.jpg&quot; /&gt;
	&lt;figcaption&gt;This is how a habit loop looks like.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The first part is a cue, something that triggers a habit. For alcoholics, feeling anxious is often a cue to get sloshed. The cue triggers a routine ( the process of getting drunk ), and this leads to a reward, which is a feeling of relaxation in our alcoholic case. The most interesting part, however, is the ‘craving’. After a person has gone through a habit loop, several time, he start craving the routine, instead of the reward! This set of a vicious cycle (in case of our alcoholic case), but can be something very useful if the habit happens to be a good one (like going out of a run in the morning).&lt;/p&gt;

&lt;p&gt;The golder rule to change a habit: Keep the cue and the reward, just change the routine. This is how people who join ‘Alcoholics Anonymous’ are able to get rid of their addiction. They basically change the routine ( by talking to their sponsor or attending a meeting instead of drinking) whenever they feel a cue (getting stressed for example). The reward remains the same (feeling relaxed).&lt;/p&gt;

&lt;p&gt;This post is quite unstructured, and I will probably re-write it whenever I get a little more time to organize my thoughts. &lt;/p&gt;

&lt;p&gt;For those of you to lazy to read the book, you can have a look at the following video:&lt;/p&gt;

&lt;iframe width=&quot;640&quot; height=&quot;390&quot; src=&quot;//www.youtube.com/embed/7vubNNfhSvc&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

  &lt;p&gt;&lt;a href=&quot;http://home.iitk.ac.in/~avisingh/%5B%22review%22%5D/the-power-of-habit-1-slash-3/&quot;&gt;The Power of Habit [1/3]&lt;/a&gt; was originally published by Avi Singh at &lt;a href=&quot;http://home.iitk.ac.in/~avisingh&quot;&gt;Trailblazer&lt;/a&gt; on September 30, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Visual Odometry(Part 1)]]></title>
  <link rel="alternate" type="text/html" href="http://home.iitk.ac.in/~avisingh/%5B%22vision%22%5D/visual-odometry-part-1/" />
  <id>http://home.iitk.ac.in/~avisingh/%5B%22vision%22%5D/visual-odometry-part-1</id>
  <updated>2014-07-29 05:38:43 +0000T00:00:00-00:00</updated>
  <published>2014-07-29T00:00:00+00:00</published>
  
  <author>
    <name>Avi Singh</name>
    <uri>http://home.iitk.ac.in/~avisingh</uri>
    <email>avisingh599@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;I am thinking of taking up a project on ‘Visual Odometry’ as UGP-1 (Undergraduate Project) here in my fifth semester at IIT-Kanpur.
This post is primarily a list of some useful links which will get on acquainted with the basics of Visual Odometry.&lt;/p&gt;

&lt;p&gt;The first thing that anyone should read is this wonderful two-part review by Davide Scaramuzza and Friedrich Fraundorfer:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.roboticsschool.ethz.ch/airobots/programme/presentations/VO_part_I.pdf&quot;&gt;Visual Odometry Tutorial Part 1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://rpg.ifi.uzh.ch/docs/VO_Part_II_Scaramuzza.pdf&quot;&gt;Visual Odometry Tutorial Part 2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One thing that I did not understand from the above tutorials was the ‘5-point algorithm’ by Nister in 2003. The original paper is &lt;a href=&quot;http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1288525&quot;&gt;here&lt;/a&gt;. But, this paper also seemed quite complicated for me to implement without any background, so I moved onto a simpler algorithm, called the ‘8-point algorithm’, which was published a long time ago by Longuet-Higgins. You can find it &lt;a href=&quot;http://www2.ece.ohio-state.edu/~aleix/Longuet-Higgins.pdf&quot;&gt;here&lt;/a&gt;. There are some lecture slides which explain this in a simple manner, and you can find them &lt;a href=&quot;http://www.cse.psu.edu/~rcollins/CSE486/lecture20_6pp.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Note, there are more papers that one should read regarding this, most notably:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cse.unr.edu/~bebis/CS485/Handouts/hartley.pdf&quot;&gt;In Defense of the 8-point Algorithmm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://users.cecs.anu.edu.au/~hongdong/new5pt_cameraREady_ver_1.pdf&quot;&gt;5-point Motion Estimation Made Easy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In my next post, I will hopefully start working on my implementation.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://home.iitk.ac.in/~avisingh/%5B%22vision%22%5D/visual-odometry-part-1/&quot;&gt;Visual Odometry(Part 1)&lt;/a&gt; was originally published by Avi Singh at &lt;a href=&quot;http://home.iitk.ac.in/~avisingh&quot;&gt;Trailblazer&lt;/a&gt; on July 29, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Quotes]]></title>
  <link rel="alternate" type="text/html" href="http://home.iitk.ac.in/~avisingh/%5B%5D/quotes/" />
  <id>http://home.iitk.ac.in/~avisingh/%5B%5D/quotes</id>
  <updated>2014-07-26 13:32:24 +0000T00:00:00-00:00</updated>
  <published>2014-07-26T00:00:00+00:00</published>
  
  <author>
    <name>Avi Singh</name>
    <uri>http://home.iitk.ac.in/~avisingh</uri>
    <email>avisingh599@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;I will keep updating this page with quotes (and occasionally poems) that I find most memorable, and worth noting down.&lt;/p&gt;

&lt;p&gt;Starting with poems first, this poem by William Ernest Henley is my personal favourite.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Out of the night that covers me,&lt;br /&gt;
Black as the Pit from pole to pole,&lt;br /&gt;
I thank whatever gods may be&lt;br /&gt;
For my unconquerable soul.&lt;br /&gt;
In the fell clutch of circumstance&lt;br /&gt;
I have not winced nor cried aloud.&lt;br /&gt;
Under the bludgeoning of chance&lt;br /&gt;
My head is bloody, but unbowed.&lt;br /&gt;
Beyond this place of wrath and tears&lt;br /&gt;
Looms but the Horror of the shade,&lt;br /&gt;
And yet the menace of the years&lt;br /&gt;
Finds, and shall find, me unafraid.&lt;br /&gt;
It matters not how strait the gate,&lt;br /&gt;
How charged with punishments the scroll.&lt;br /&gt;
I am the master of my fate:&lt;br /&gt;
I am the captain of my soul.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Another one that I particularly like (though it is not inspiring in any way) is this one by Robert Frost.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Some say the world will end in fire,&lt;br /&gt;
Some say in ice.&lt;br /&gt;
From what I’ve tasted of desire&lt;br /&gt;
I hold with those who favor fire.&lt;br /&gt;
But if it had to perish twice,&lt;br /&gt;
I think I know enough of hate&lt;br /&gt;
To say that for destruction ice&lt;br /&gt;
Is also great&lt;br /&gt;
And would suffice.&lt;/p&gt;
&lt;/blockquote&gt;


  &lt;p&gt;&lt;a href=&quot;http://home.iitk.ac.in/~avisingh/%5B%5D/quotes/&quot;&gt;Quotes&lt;/a&gt; was originally published by Avi Singh at &lt;a href=&quot;http://home.iitk.ac.in/~avisingh&quot;&gt;Trailblazer&lt;/a&gt; on July 26, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[RANSAC]]></title>
  <link rel="alternate" type="text/html" href="http://home.iitk.ac.in/~avisingh/%5B%22math%22%5D/ransac/" />
  <id>http://home.iitk.ac.in/~avisingh/%5B%22math%22%5D/ransac</id>
  <updated>2014-07-21 01:48:52 +0000T00:00:00-00:00</updated>
  <published>2014-07-21T00:00:00+00:00</published>
  
  <author>
    <name>Avi Singh</name>
    <uri>http://home.iitk.ac.in/~avisingh</uri>
    <email>avisingh599@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;This post is about the popular outlier rejection algorithm RANSAC. It stands for RANdom SAmple Consensus. It is widely used in computer vision, with one of the application being in rejection of false feature matches in a pair of images from a stereo camera set.&lt;/p&gt;

&lt;p&gt;Suppose you have been given a dataset and you want to fit a mathematical model on it. We now assume that this data has certain &lt;em&gt;inliers&lt;/em&gt; and some &lt;em&gt;outliers&lt;/em&gt;. Inliers refer to the data points whose presence can be explained with the help of a mathematical model, while outliers are data points whose presence can never be explained via any reasonable mathematical model. Usually their presence in the dataset deteriorates the quality of the mathematical model that we can fit to the data. For best results, we should ignore these outliers while estimating the parameters of our mathematical model. RANSAC helps us in identifying these points so that we can obtain a better fir for the inliers.&lt;/p&gt;

&lt;p&gt;Note that even the inliers do not &lt;em&gt;exactly&lt;/em&gt; fit the mathematical model as they might have some noise, but the outliers either have an extremely large amount of noise or they are obtained due to faults in measurement, or because of problems in the sensor from which we are obtaining the data.&lt;/p&gt;

&lt;h2 id=&quot;the-algorithm&quot;&gt;The Algorithm&lt;/h2&gt;

&lt;h3 id=&quot;the-input&quot;&gt;The Input&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Data points&lt;/li&gt;
  &lt;li&gt;Some parametrized model (we need to estimate the parameters for this model)&lt;/li&gt;
  &lt;li&gt;Some confidence parameters&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;algo&quot;&gt;Algo&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;A set points from the original dataset are randomly selected, and are assumed to be the inliers.&lt;/li&gt;
  &lt;li&gt;Parameters are estimated to fit to this hypothetical inlier set.&lt;/li&gt;
  &lt;li&gt;Every point that was not a part of this hypothetical inlier set is tested against the mathematical model that we just fit.&lt;/li&gt;
  &lt;li&gt;The points that fit the model become a part of the &lt;em&gt;consensus&lt;/em&gt; set. The model is good if a particular number of points have been classified as part of the consensus set.&lt;/li&gt;
  &lt;li&gt;This model is then re-estimated using all the members of a consensus set.&lt;/li&gt;
  &lt;li&gt;The above process is repeated a fixed number of times, and the model with the largest consensus set is kept.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-many-times-do-we-repeat&quot;&gt;How many times do we repeat?&lt;/h3&gt;
&lt;p&gt;It is possible to theoretically determine the fixed number of iterations ‘k’ which are needed, if we have an estimate of the percentage of outliers present in the data.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://home.iitk.ac.in/~avisingh/%5B%22math%22%5D/ransac/&quot;&gt;RANSAC&lt;/a&gt; was originally published by Avi Singh at &lt;a href=&quot;http://home.iitk.ac.in/~avisingh&quot;&gt;Trailblazer&lt;/a&gt; on July 21, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Parallel Programming with CUDA]]></title>
  <link rel="alternate" type="text/html" href="http://home.iitk.ac.in/~avisingh/%5B%22gpu%22%5D/parallel-programming-with-cuda/" />
  <id>http://home.iitk.ac.in/~avisingh/%5B%22gpu%22%5D/parallel-programming-with-cuda</id>
  <updated>2014-07-20 20:18:16 +0000T00:00:00-00:00</updated>
  <published>2014-07-21T00:00:00+00:00</published>
  
  <author>
    <name>Avi Singh</name>
    <uri>http://home.iitk.ac.in/~avisingh</uri>
    <email>avisingh599@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;I recently started going through an amazing Udacity course on Parallel Programming. Having been working on image processing and computer vision for quite some time now, I have realized that CPUs are NOT designed for image processing applications. Even the oh-so-optimized OpenCV implementations of computer vision algorithms in C/C++ do not give a good speed when working on something as computationally expensive as variational optical flow. However, if you use the inbuilt CUDA module (in OpenCV 3.0), the performance is &lt;em&gt;way&lt;/em&gt; better.&lt;/p&gt;

&lt;h2 id=&quot;why-gpus&quot;&gt;Why GPUs?&lt;/h2&gt;

&lt;p&gt;CPUs are not getting any faster, due to limitation of clock speeds which have virtually remained the same since the past 5 years or so. Increasing this clock speed has become close to impossible, since increasing clock speeds increases the power consumption, which makes it difficult to cool the CPU. So, for faster computations, GPUs are the way to go.&lt;/p&gt;

&lt;h2 id=&quot;gpu-vs-cpu&quot;&gt;GPU vs CPU&lt;/h2&gt;

&lt;p&gt;My computer has a quad-core processor with hyper threading (an Intel i7 Ivy Bridge). This means that, in the best case, I can have at most 8-threads truly running in parallel. On the other hand, the low-end GPU that I have (nVidia GeForce GT630M) has 96 cores!&lt;/p&gt;

&lt;p&gt;In general, a CPU has a few, very powerful computation cores, where as a GPU has a very large number of smaller, less powerful computation cores. The time taken to perform any one particular task is less on the CPU, but if you need to performs thousands of such tasks, then the GPU would beat the CPU.&lt;/p&gt;

&lt;p&gt;One more important thing to note is that, while designing CPUs engineers optimize for &lt;em&gt;latency&lt;/em&gt;. On the other hand, maximum &lt;em&gt;thorughput&lt;/em&gt; is what the designers are aiming at while making GPUs.&lt;/p&gt;

&lt;h2 id=&quot;throughput-vs-latency&quot;&gt;Throughput vs Latency&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Throughput: It is defined as the amount of work done in unit time. For example, I need to transport 50 bags of rice from ground floor of a building to the 10th floor, and I can carry at most two bags at a time. Let the time taken in each trip be 5 minutes. So, the amount of work done in one hour would be 2*(60/5) = 24 bags. I can say that the throughput is 24 bags/hr.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Latency: It is defined as the amount of time taken to perform a particular task. In the previous example, it would take take 125 minutes to take all the 50 bags, and hence the latency (measures in time units) is 125 minutes.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cuda&quot;&gt;CUDA&lt;/h2&gt;

&lt;p&gt;CUDA is a framework developed by nVidia for writing programs that run both on the GPU and the CPU. On the CPU side, you can write programs in C, and then used some extensions to C (written by nVidia) to write programs that run on the GPU. These programs that run on the GPU are called &lt;em&gt;kernels&lt;/em&gt;. A kernel looks like a serial program, but the CPU launches on a large  number of threads on the GPU. In CUDA, the CPU is referred to as the &lt;em&gt;host&lt;/em&gt; while the GPU is referred to as the &lt;em&gt;device&lt;/em&gt;. In this relationship between the CPU and the GPU, the CPU is the &lt;em&gt;alpha&lt;/em&gt;. The CPU and the GPU have separate memories, and can perform operations only on the data that is stored in their own memory. The CPU can allocate memory on the GPU, copy data from the CPU memory to the GPU memory, launch kernels on hundreds of thread on the GPU, and copy back the results from the GPU memory. The GPU, on the other hand, can only respond to call of memory copy made by the CPU, and cannot make its own requests for data transfer.&lt;/p&gt;

&lt;h4 id=&quot;skeleton-of-a-cuda-program&quot;&gt;Skeleton of a CUDA program:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Allocate memory on the GPU&lt;/li&gt;
  &lt;li&gt;Transfer data from the CPU memory to the GPU memory&lt;/li&gt;
  &lt;li&gt;Perform the computations on the GPU&lt;/li&gt;
  &lt;li&gt;Copy the results from the GPU to the CPU&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A sample code in CUDA, which calculates the cubes of all integers from 1 to 64.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;c&quot;&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// here is the kernel&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;__global__&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cube&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;// Todo: Fill in this function&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;d_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// threadIdx is a C struct having members x,y,z, other structs available are blockIdx, threaddim, blockdim&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//__global__ is what specifies that the fucntion is a kernel&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_BYTES&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sizeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// generate the input array on the host&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ARRAY_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;h_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ARRAY_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// declare GPU memory pointers&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// allocate GPU memory&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cudaMalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_BYTES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cudaMalloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_BYTES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// transfer the array to the GPU&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_BYTES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// launch the kernel&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cube&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_SIZE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;cm&quot;&gt;/*&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;	One block of 64 threads is being launched here. We specify the number of blocks as well as the number of threads in each block.&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;	Each block has a limited number of threads that it can support. Modern GPUs support 1024, older support 512.&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;	Can have any number of blocks. Cuda supports 2D and 3D arrangement of blocks as well.&lt;/span&gt;
&lt;span class=&quot;cm&quot;&gt;	*/&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// copy back the result array to the CPU&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_BYTES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cudaMemcpyDeviceToHost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// print out the resulting array&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ARRAY_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;%f&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;cudaFree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cudaFree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If you have the nVidia CUDA toolkit installed, you can compile and run the above program using:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;nvcc -o sample sample.c
./sample&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


  &lt;p&gt;&lt;a href=&quot;http://home.iitk.ac.in/~avisingh/%5B%22gpu%22%5D/parallel-programming-with-cuda/&quot;&gt;Parallel Programming with CUDA&lt;/a&gt; was originally published by Avi Singh at &lt;a href=&quot;http://home.iitk.ac.in/~avisingh&quot;&gt;Trailblazer&lt;/a&gt; on July 21, 2014.&lt;/p&gt;</content>
</entry>

</feed>
